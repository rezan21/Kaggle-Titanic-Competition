{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# notes \n",
    "df[\"firstname\"] = df[\"Name\"].apply(lambda x : x.split(\",\")[0]) # extract firstname\n",
    "df[\"salutation\"] = df[\"Name\"].apply(lambda x:x.split(\",\")[-1].split(\".\")[0]) # extract salutation e.g: mr,mrs,dr,...\n",
    "df[\"lastname\"] = df[\"Name\"].apply(lambda x:x.split(\",\")[-1].split(\".\")[-1]) # extract last name\n",
    "df.drop(\"Name\", 1, inplace=True) # already processed\n",
    "df.head()\n",
    "\n",
    "df.dropna(subset=[\"Embarked\"], inplace=True)\n",
    "\n",
    "sns.countplot(x=\"Sex\", hue=\"Survived\", data=df)\n",
    "\n",
    "#1-hot-encode Pclass\n",
    "pclass_encoded = pd.get_dummies(df[\"Pclass\"])\n",
    "pclass_encoded.head()\n",
    "\n",
    "#sns.boxplot(y=\"Age\",x=\"SibSp\",data=df)\n",
    "#sns.heatmap(df.corr())\n",
    "'''\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable gpu\n",
    "# Kaggle setting:\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping # controlling loss\n",
    "\n",
    "SEED = 111\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED) # Constant python seed\n",
    "np.random.seed(SEED) # Constant numpy seed\n",
    "tf.random.set_seed(SEED) # Constant tensorflow seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (891, 12) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "print(f\"Dataset Shape: {df.shape} \\n\")\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "----------------------\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "----------------------\n",
      "Williams, Mr. Howard Hugh \"Harry\"              1\n",
      "Gustafsson, Mr. Karl Gideon                    1\n",
      "Danoff, Mr. Yoto                               1\n",
      "Peter, Mrs. Catherine (Catherine Rizk)         1\n",
      "Shorney, Mr. Charles Joseph                    1\n",
      "                                              ..\n",
      "LeRoy, Miss. Bertha                            1\n",
      "Johnson, Mr. Malkolm Joackim                   1\n",
      "Chibnall, Mrs. (Edith Martha Bowerman)         1\n",
      "Tobin, Mr. Roger                               1\n",
      "Clarke, Mrs. Charles V (Ada Maria Winfield)    1\n",
      "Name: Name, Length: 891, dtype: int64\n",
      "----------------------\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "----------------------\n",
      "24.00    30\n",
      "22.00    27\n",
      "18.00    26\n",
      "19.00    25\n",
      "30.00    25\n",
      "         ..\n",
      "55.50     1\n",
      "70.50     1\n",
      "66.00     1\n",
      "23.50     1\n",
      "0.42      1\n",
      "Name: Age, Length: 88, dtype: int64\n",
      "----------------------\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "----------------------\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "----------------------\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "347088      6\n",
      "           ..\n",
      "A/S 2816    1\n",
      "36568       1\n",
      "29105       1\n",
      "3460        1\n",
      "2628        1\n",
      "Name: Ticket, Length: 681, dtype: int64\n",
      "----------------------\n",
      "8.0500     43\n",
      "13.0000    42\n",
      "7.8958     38\n",
      "7.7500     34\n",
      "26.0000    31\n",
      "           ..\n",
      "8.4583      1\n",
      "9.8375      1\n",
      "8.3625      1\n",
      "14.1083     1\n",
      "17.4000     1\n",
      "Name: Fare, Length: 248, dtype: int64\n",
      "----------------------\n",
      "C23 C25 C27    4\n",
      "B96 B98        4\n",
      "G6             4\n",
      "F33            3\n",
      "C22 C26        3\n",
      "              ..\n",
      "A19            1\n",
      "A32            1\n",
      "C106           1\n",
      "B78            1\n",
      "B50            1\n",
      "Name: Cabin, Length: 147, dtype: int64\n",
      "----------------------\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Survived</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pclass</td>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns[1:]:\n",
    "    print(df[col].value_counts())\n",
    "    print(\"----------------------\")\n",
    "\n",
    "df.drop(\"Ticket\", 1, inplace=True) # lots of randomness. seems has no relation to other cols. too many uniques to be 1-hot-encoded\n",
    "df.drop(\"Name\", 1, inplace=True) # too many uniques to be 1-hot-encoded. can be used in future modellings\n",
    "\n",
    "df.describe().T # stats of numerical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% missings in cols:\n",
      "Age         19.865320\n",
      "Cabin       77.104377\n",
      "Embarked     0.224467\n",
      "dtype: float64\n",
      "----------------------\n",
      "droped column Cabin \n",
      "replaced NA of Embarked with mode\n",
      "replaced NA of Age with median\n",
      "----------------------\n",
      "% missings in cols:\n",
      "Series([], dtype: float64) 2\n",
      "Dataset Shape: (891, 9) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0            1         0       3    male  22.0      1      0   7.2500        S\n",
       "1            2         1       1  female  38.0      1      0  71.2833        C\n",
       "2            3         1       3  female  26.0      0      0   7.9250        S\n",
       "3            4         1       1  female  35.0      1      0  53.1000        S\n",
       "4            5         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values treatment:\n",
    "print(\"% missings in cols:\")\n",
    "print(df.isnull().sum()[df.isnull().sum()>0]/df.shape[0]*100)\n",
    "print(\"----------------------\")\n",
    "\n",
    "# 1- drop Cabin as majority of column is empty. Also it seems there's no way to retrieve NAs\n",
    "df.drop(\"Cabin\", 1, inplace=True) # \n",
    "print(\"droped column Cabin \")\n",
    "\n",
    "# 2- fill NA of Embarked with its mode\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(value=df[\"Embarked\"].mode()[0])\n",
    "print(\"replaced NA of Embarked with mode\")\n",
    "\n",
    "\n",
    "# 3- fill NA of Age with its median\n",
    "df[\"Age\"] = df[\"Age\"].fillna(value=df[\"Age\"].median())\n",
    "#df[\"Age\"][df[\"SibSp\"]==0]=df[\"Age\"][df[\"SibSp\"]==0].fillna(value=df[\"Age\"][df[\"SibSp\"]==0].mean())\n",
    "#df[\"Age\"][df[\"SibSp\"]==1]=df[\"Age\"][df[\"SibSp\"]==1].fillna(value=df[\"Age\"][df[\"SibSp\"]==1].mean())\n",
    "#df[\"Age\"][df[\"SibSp\"]==2]=df[\"Age\"][df[\"SibSp\"]==2].fillna(value=df[\"Age\"][df[\"SibSp\"]==2].mean())\n",
    "#df[\"Age\"][df[\"SibSp\"]==3]=df[\"Age\"][df[\"SibSp\"]==3].fillna(value=df[\"Age\"][df[\"SibSp\"]==3].mean())\n",
    "#df[\"Age\"][df[\"SibSp\"]==4]=df[\"Age\"][df[\"SibSp\"]==4].fillna(value=df[\"Age\"][df[\"SibSp\"]==4].mean())\n",
    "#df[\"Age\"][df[\"SibSp\"]==5]=df[\"Age\"][df[\"SibSp\"]==5].fillna(value=df[\"Age\"][df[\"SibSp\"]==5].mean())\n",
    "#df[\"Age\"] = df[\"Age\"].fillna(value=df[\"Age\"].mean())\n",
    "print(\"replaced NA of Age with median\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "\n",
    "print(\"% missings in cols:\")\n",
    "print(round(df.isnull().sum()[df.isnull().sum()>0]/df.shape[0]*100),2)\n",
    "print(f\"Dataset Shape: {df.shape} \\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (891, 11) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.7125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch      Fare  C  Q  S\n",
       "0          375         0       3    0   3.0      3      1   21.0750  0  0  1\n",
       "1          212         1       2    0  35.0      0      0   21.0000  0  0  1\n",
       "2          259         1       1    0  35.0      0      0  512.3292  1  0  0\n",
       "3          585         0       3    1  28.0      0      0    8.7125  1  0  0\n",
       "4          462         0       3    1  34.0      0      0    8.0500  0  0  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-hot-encoding:\n",
    "# Sex\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\":1, \"female\":0}) # male = 1 / female = 0\n",
    "\n",
    "# Embarked\n",
    "embarked_encoded = pd.get_dummies(df[\"Embarked\"])\n",
    "\n",
    "# Pclass\n",
    "#pclass_encoded = pd.get_dummies(df[\"Pclass\"],prefix=\"class_\")\n",
    "\n",
    "#df.drop([\"Embarked\",\"Pclass\"],axis=1,inplace=True) # drop uncoded cols\n",
    "#df = pd.concat([df,embarked_encoded,pclass_encoded],axis=1) # concat encoded ones\n",
    "df.drop([\"Embarked\"],axis=1,inplace=True) # drop uncoded cols\n",
    "df = pd.concat([df,embarked_encoded],axis=1) # concat encoded ones\n",
    "\n",
    "# shuffle data\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# save data file\n",
    "df.to_csv('df_v1.csv',index=False)\n",
    "print(f\"Dataset Shape: {df.shape} \\n\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: X1_train:(801, 9), X1_test:(90, 9), y1_train:(801,), y1_test:(90,)\n"
     ]
    }
   ],
   "source": [
    "#modeling:\n",
    "df_v1 = pd.read_csv(\"df_v1.csv\")\n",
    "\n",
    "# Features & Labels\n",
    "X1 = df_v1.drop([\"PassengerId\", \"Survived\"], axis=1).values\n",
    "y1 = df_v1[\"Survived\"].values\n",
    "\n",
    "# train/test split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.1\n",
    "                                                        , random_state=SEED\n",
    "                                                       )\n",
    "print(f\"shapes: X1_train:{X1_train.shape}, X1_test:{X1_test.shape}, y1_train:{y1_train.shape}, y1_test:{y1_test.shape}\")\n",
    "\n",
    "# scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1_train)\n",
    "X1_train_s = scaler.transform(X1_train)\n",
    "X1_test_s = scaler.transform(X1_test)\n",
    "\n",
    "# model\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "     \n",
    "    model.add(Dense(units=5, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "   \n",
    "    '''\n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(units=17, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(units=9, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    \n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dnnClf = build_model()\n",
    "\n",
    "# early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 1/1000\n",
      "801/801 [==============================] - 2s 2ms/sample - loss: 0.7721 - accuracy: 0.5094 - val_loss: 0.6859 - val_accuracy: 0.5778\n",
      "Epoch 2/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.7395 - accuracy: 0.5793 - val_loss: 0.6741 - val_accuracy: 0.5444\n",
      "Epoch 3/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.7095 - accuracy: 0.6092 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
      "Epoch 4/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.6825 - accuracy: 0.6467 - val_loss: 0.6587 - val_accuracy: 0.6333\n",
      "Epoch 5/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.6726 - accuracy: 0.6504 - val_loss: 0.6562 - val_accuracy: 0.6556\n",
      "Epoch 6/1000\n",
      "801/801 [==============================] - 0s 182us/sample - loss: 0.6681 - accuracy: 0.6729 - val_loss: 0.6515 - val_accuracy: 0.6778\n",
      "Epoch 7/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.6562 - accuracy: 0.6941 - val_loss: 0.6434 - val_accuracy: 0.7000\n",
      "Epoch 8/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.6607 - accuracy: 0.6729 - val_loss: 0.6368 - val_accuracy: 0.6778\n",
      "Epoch 9/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.6548 - accuracy: 0.6679 - val_loss: 0.6313 - val_accuracy: 0.6778\n",
      "Epoch 10/1000\n",
      "801/801 [==============================] - 0s 168us/sample - loss: 0.6375 - accuracy: 0.6866 - val_loss: 0.6238 - val_accuracy: 0.6889\n",
      "Epoch 11/1000\n",
      "801/801 [==============================] - 0s 168us/sample - loss: 0.6359 - accuracy: 0.6754 - val_loss: 0.6153 - val_accuracy: 0.7000\n",
      "Epoch 12/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6364 - accuracy: 0.6767 - val_loss: 0.6121 - val_accuracy: 0.7111\n",
      "Epoch 13/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6287 - accuracy: 0.6854 - val_loss: 0.6053 - val_accuracy: 0.7222\n",
      "Epoch 14/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.6308 - accuracy: 0.7041 - val_loss: 0.6007 - val_accuracy: 0.7444\n",
      "Epoch 15/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.6231 - accuracy: 0.6866 - val_loss: 0.5990 - val_accuracy: 0.7333\n",
      "Epoch 16/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.6303 - accuracy: 0.6779 - val_loss: 0.5984 - val_accuracy: 0.7000\n",
      "Epoch 17/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.6158 - accuracy: 0.6904 - val_loss: 0.5937 - val_accuracy: 0.7222\n",
      "Epoch 18/1000\n",
      "801/801 [==============================] - 0s 170us/sample - loss: 0.6242 - accuracy: 0.6804 - val_loss: 0.5923 - val_accuracy: 0.7111\n",
      "Epoch 19/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.6046 - accuracy: 0.7066 - val_loss: 0.5845 - val_accuracy: 0.7333\n",
      "Epoch 20/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.6170 - accuracy: 0.6891 - val_loss: 0.5822 - val_accuracy: 0.7333\n",
      "Epoch 21/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6066 - accuracy: 0.6879 - val_loss: 0.5828 - val_accuracy: 0.7111\n",
      "Epoch 22/1000\n",
      "801/801 [==============================] - 0s 170us/sample - loss: 0.6049 - accuracy: 0.6904 - val_loss: 0.5802 - val_accuracy: 0.7111\n",
      "Epoch 23/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5981 - accuracy: 0.6966 - val_loss: 0.5754 - val_accuracy: 0.7222\n",
      "Epoch 24/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.6094 - accuracy: 0.6891 - val_loss: 0.5713 - val_accuracy: 0.7333\n",
      "Epoch 25/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.6152 - accuracy: 0.6792 - val_loss: 0.5692 - val_accuracy: 0.7333\n",
      "Epoch 26/1000\n",
      "801/801 [==============================] - 0s 168us/sample - loss: 0.6025 - accuracy: 0.7091 - val_loss: 0.5673 - val_accuracy: 0.7333\n",
      "Epoch 27/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.6126 - accuracy: 0.6941 - val_loss: 0.5633 - val_accuracy: 0.7556\n",
      "Epoch 28/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6026 - accuracy: 0.7004 - val_loss: 0.5659 - val_accuracy: 0.7444\n",
      "Epoch 29/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.6027 - accuracy: 0.7004 - val_loss: 0.5666 - val_accuracy: 0.7444\n",
      "Epoch 30/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.6193 - accuracy: 0.6904 - val_loss: 0.5665 - val_accuracy: 0.7333\n",
      "Epoch 31/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.6135 - accuracy: 0.6916 - val_loss: 0.5665 - val_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "801/801 [==============================] - 0s 263us/sample - loss: 0.5995 - accuracy: 0.7054 - val_loss: 0.5681 - val_accuracy: 0.7222\n",
      "Epoch 33/1000\n",
      "801/801 [==============================] - 0s 236us/sample - loss: 0.5971 - accuracy: 0.7129 - val_loss: 0.5667 - val_accuracy: 0.7222\n",
      "Epoch 34/1000\n",
      "801/801 [==============================] - 0s 219us/sample - loss: 0.5961 - accuracy: 0.7029 - val_loss: 0.5675 - val_accuracy: 0.7000\n",
      "Epoch 35/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5999 - accuracy: 0.7041 - val_loss: 0.5662 - val_accuracy: 0.7000\n",
      "Epoch 36/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.6047 - accuracy: 0.7066 - val_loss: 0.5628 - val_accuracy: 0.7222\n",
      "Epoch 37/1000\n",
      "801/801 [==============================] - 0s 270us/sample - loss: 0.6047 - accuracy: 0.6891 - val_loss: 0.5619 - val_accuracy: 0.7222\n",
      "Epoch 38/1000\n",
      "801/801 [==============================] - 0s 245us/sample - loss: 0.6004 - accuracy: 0.7091 - val_loss: 0.5579 - val_accuracy: 0.7222\n",
      "Epoch 39/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5966 - accuracy: 0.7054 - val_loss: 0.5522 - val_accuracy: 0.7556\n",
      "Epoch 40/1000\n",
      "801/801 [==============================] - 0s 170us/sample - loss: 0.5994 - accuracy: 0.7054 - val_loss: 0.5497 - val_accuracy: 0.7556\n",
      "Epoch 41/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6025 - accuracy: 0.7066 - val_loss: 0.5439 - val_accuracy: 0.7889\n",
      "Epoch 42/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5965 - accuracy: 0.6979 - val_loss: 0.5447 - val_accuracy: 0.7778\n",
      "Epoch 43/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.6009 - accuracy: 0.6954 - val_loss: 0.5495 - val_accuracy: 0.7556\n",
      "Epoch 44/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.6198 - accuracy: 0.6979 - val_loss: 0.5515 - val_accuracy: 0.7667\n",
      "Epoch 45/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.5875 - accuracy: 0.7154 - val_loss: 0.5512 - val_accuracy: 0.7667\n",
      "Epoch 46/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5893 - accuracy: 0.7141 - val_loss: 0.5480 - val_accuracy: 0.7667\n",
      "Epoch 47/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.6085 - accuracy: 0.6767 - val_loss: 0.5502 - val_accuracy: 0.7667\n",
      "Epoch 48/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5986 - accuracy: 0.7004 - val_loss: 0.5514 - val_accuracy: 0.7556\n",
      "Epoch 49/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5871 - accuracy: 0.7091 - val_loss: 0.5477 - val_accuracy: 0.7667\n",
      "Epoch 50/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.6014 - accuracy: 0.6979 - val_loss: 0.5485 - val_accuracy: 0.7667\n",
      "Epoch 51/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.6123 - accuracy: 0.7029 - val_loss: 0.5518 - val_accuracy: 0.7444\n",
      "Epoch 52/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5948 - accuracy: 0.7004 - val_loss: 0.5500 - val_accuracy: 0.7667\n",
      "Epoch 53/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5967 - accuracy: 0.7104 - val_loss: 0.5456 - val_accuracy: 0.7667\n",
      "Epoch 54/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5965 - accuracy: 0.6904 - val_loss: 0.5460 - val_accuracy: 0.7667\n",
      "Epoch 55/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5748 - accuracy: 0.7116 - val_loss: 0.5450 - val_accuracy: 0.7667\n",
      "Epoch 56/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5877 - accuracy: 0.7066 - val_loss: 0.5418 - val_accuracy: 0.7667\n",
      "Epoch 57/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5920 - accuracy: 0.7141 - val_loss: 0.5386 - val_accuracy: 0.7778\n",
      "Epoch 58/1000\n",
      "801/801 [==============================] - 0s 185us/sample - loss: 0.5919 - accuracy: 0.6929 - val_loss: 0.5374 - val_accuracy: 0.7778\n",
      "Epoch 59/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5782 - accuracy: 0.7191 - val_loss: 0.5350 - val_accuracy: 0.7889\n",
      "Epoch 60/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5875 - accuracy: 0.6991 - val_loss: 0.5352 - val_accuracy: 0.7889\n",
      "Epoch 61/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5949 - accuracy: 0.7029 - val_loss: 0.5347 - val_accuracy: 0.7778\n",
      "Epoch 62/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5866 - accuracy: 0.7166 - val_loss: 0.5336 - val_accuracy: 0.7889\n",
      "Epoch 63/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5738 - accuracy: 0.7129 - val_loss: 0.5255 - val_accuracy: 0.8111\n",
      "Epoch 64/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.5913 - accuracy: 0.6991 - val_loss: 0.5263 - val_accuracy: 0.8111\n",
      "Epoch 65/1000\n",
      "801/801 [==============================] - 0s 171us/sample - loss: 0.5858 - accuracy: 0.7041 - val_loss: 0.5329 - val_accuracy: 0.7778\n",
      "Epoch 66/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5869 - accuracy: 0.7166 - val_loss: 0.5284 - val_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.6033 - accuracy: 0.6854 - val_loss: 0.5250 - val_accuracy: 0.8111\n",
      "Epoch 68/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.6102 - accuracy: 0.6879 - val_loss: 0.5273 - val_accuracy: 0.8111\n",
      "Epoch 69/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5849 - accuracy: 0.7116 - val_loss: 0.5250 - val_accuracy: 0.8111\n",
      "Epoch 70/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5719 - accuracy: 0.7141 - val_loss: 0.5198 - val_accuracy: 0.8111\n",
      "Epoch 71/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5934 - accuracy: 0.7079 - val_loss: 0.5175 - val_accuracy: 0.8111\n",
      "Epoch 72/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5851 - accuracy: 0.7129 - val_loss: 0.5198 - val_accuracy: 0.8111\n",
      "Epoch 73/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5765 - accuracy: 0.7154 - val_loss: 0.5167 - val_accuracy: 0.8111\n",
      "Epoch 74/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5768 - accuracy: 0.7166 - val_loss: 0.5119 - val_accuracy: 0.8111\n",
      "Epoch 75/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5729 - accuracy: 0.7166 - val_loss: 0.5095 - val_accuracy: 0.8111\n",
      "Epoch 76/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5600 - accuracy: 0.7191 - val_loss: 0.5080 - val_accuracy: 0.8111\n",
      "Epoch 77/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5794 - accuracy: 0.7091 - val_loss: 0.5076 - val_accuracy: 0.8111\n",
      "Epoch 78/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5892 - accuracy: 0.7029 - val_loss: 0.5062 - val_accuracy: 0.8111\n",
      "Epoch 79/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5792 - accuracy: 0.7029 - val_loss: 0.5091 - val_accuracy: 0.8111\n",
      "Epoch 80/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.6095 - accuracy: 0.6941 - val_loss: 0.5133 - val_accuracy: 0.8111\n",
      "Epoch 81/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5664 - accuracy: 0.7203 - val_loss: 0.5119 - val_accuracy: 0.8111\n",
      "Epoch 82/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5899 - accuracy: 0.7116 - val_loss: 0.5144 - val_accuracy: 0.8111\n",
      "Epoch 83/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5883 - accuracy: 0.7066 - val_loss: 0.5143 - val_accuracy: 0.8111\n",
      "Epoch 84/1000\n",
      "801/801 [==============================] - 0s 186us/sample - loss: 0.5744 - accuracy: 0.7079 - val_loss: 0.5103 - val_accuracy: 0.8111\n",
      "Epoch 85/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5925 - accuracy: 0.6891 - val_loss: 0.5052 - val_accuracy: 0.8111\n",
      "Epoch 86/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5837 - accuracy: 0.6929 - val_loss: 0.5035 - val_accuracy: 0.8111\n",
      "Epoch 87/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5982 - accuracy: 0.6929 - val_loss: 0.5075 - val_accuracy: 0.8111\n",
      "Epoch 88/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5786 - accuracy: 0.7203 - val_loss: 0.5072 - val_accuracy: 0.8111\n",
      "Epoch 89/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5872 - accuracy: 0.7041 - val_loss: 0.5057 - val_accuracy: 0.8111\n",
      "Epoch 90/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5910 - accuracy: 0.7079 - val_loss: 0.5075 - val_accuracy: 0.8111\n",
      "Epoch 91/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5723 - accuracy: 0.7129 - val_loss: 0.5083 - val_accuracy: 0.8111\n",
      "Epoch 92/1000\n",
      "801/801 [==============================] - 0s 182us/sample - loss: 0.5678 - accuracy: 0.7228 - val_loss: 0.5063 - val_accuracy: 0.8111\n",
      "Epoch 93/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5752 - accuracy: 0.7041 - val_loss: 0.5053 - val_accuracy: 0.8111\n",
      "Epoch 94/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5887 - accuracy: 0.7054 - val_loss: 0.5041 - val_accuracy: 0.8111\n",
      "Epoch 95/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5657 - accuracy: 0.7166 - val_loss: 0.4985 - val_accuracy: 0.8111\n",
      "Epoch 96/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5821 - accuracy: 0.7029 - val_loss: 0.4986 - val_accuracy: 0.8111\n",
      "Epoch 97/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5739 - accuracy: 0.7154 - val_loss: 0.4984 - val_accuracy: 0.8111\n",
      "Epoch 98/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5975 - accuracy: 0.7041 - val_loss: 0.4988 - val_accuracy: 0.8111\n",
      "Epoch 99/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5650 - accuracy: 0.7129 - val_loss: 0.4979 - val_accuracy: 0.8111\n",
      "Epoch 100/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5788 - accuracy: 0.7041 - val_loss: 0.4934 - val_accuracy: 0.8111\n",
      "Epoch 101/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5702 - accuracy: 0.7241 - val_loss: 0.4927 - val_accuracy: 0.8111\n",
      "Epoch 102/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5753 - accuracy: 0.7016 - val_loss: 0.4907 - val_accuracy: 0.8111\n",
      "Epoch 103/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5781 - accuracy: 0.7091 - val_loss: 0.4886 - val_accuracy: 0.8111\n",
      "Epoch 104/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5841 - accuracy: 0.7104 - val_loss: 0.4885 - val_accuracy: 0.8111\n",
      "Epoch 105/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5567 - accuracy: 0.7253 - val_loss: 0.4878 - val_accuracy: 0.8111\n",
      "Epoch 106/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5760 - accuracy: 0.7091 - val_loss: 0.4893 - val_accuracy: 0.8111\n",
      "Epoch 107/1000\n",
      "801/801 [==============================] - 0s 170us/sample - loss: 0.5838 - accuracy: 0.7029 - val_loss: 0.4871 - val_accuracy: 0.8111\n",
      "Epoch 108/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5865 - accuracy: 0.7091 - val_loss: 0.4878 - val_accuracy: 0.8111\n",
      "Epoch 109/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5855 - accuracy: 0.7141 - val_loss: 0.4886 - val_accuracy: 0.8111\n",
      "Epoch 110/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5974 - accuracy: 0.6979 - val_loss: 0.4880 - val_accuracy: 0.8111\n",
      "Epoch 111/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5772 - accuracy: 0.7066 - val_loss: 0.4870 - val_accuracy: 0.8111\n",
      "Epoch 112/1000\n",
      "801/801 [==============================] - 0s 183us/sample - loss: 0.5566 - accuracy: 0.7228 - val_loss: 0.4824 - val_accuracy: 0.8111\n",
      "Epoch 113/1000\n",
      "801/801 [==============================] - 0s 172us/sample - loss: 0.5661 - accuracy: 0.7228 - val_loss: 0.4866 - val_accuracy: 0.8111\n",
      "Epoch 114/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5653 - accuracy: 0.7203 - val_loss: 0.4876 - val_accuracy: 0.8111\n",
      "Epoch 115/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5681 - accuracy: 0.7141 - val_loss: 0.4870 - val_accuracy: 0.8111\n",
      "Epoch 116/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5662 - accuracy: 0.7316 - val_loss: 0.4829 - val_accuracy: 0.8111\n",
      "Epoch 117/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5669 - accuracy: 0.6979 - val_loss: 0.4765 - val_accuracy: 0.8111\n",
      "Epoch 118/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5620 - accuracy: 0.7241 - val_loss: 0.4772 - val_accuracy: 0.8111\n",
      "Epoch 119/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5682 - accuracy: 0.7041 - val_loss: 0.4769 - val_accuracy: 0.8111\n",
      "Epoch 120/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5874 - accuracy: 0.6904 - val_loss: 0.4849 - val_accuracy: 0.8000\n",
      "Epoch 121/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5854 - accuracy: 0.7091 - val_loss: 0.4864 - val_accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "801/801 [==============================] - 0s 173us/sample - loss: 0.5730 - accuracy: 0.7066 - val_loss: 0.4860 - val_accuracy: 0.8111\n",
      "Epoch 123/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5777 - accuracy: 0.7179 - val_loss: 0.4867 - val_accuracy: 0.8000\n",
      "Epoch 124/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5891 - accuracy: 0.7141 - val_loss: 0.4890 - val_accuracy: 0.8000\n",
      "Epoch 125/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5891 - accuracy: 0.7203 - val_loss: 0.4903 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5617 - accuracy: 0.7316 - val_loss: 0.4902 - val_accuracy: 0.8000\n",
      "Epoch 127/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5970 - accuracy: 0.7066 - val_loss: 0.4896 - val_accuracy: 0.8000\n",
      "Epoch 128/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5758 - accuracy: 0.7179 - val_loss: 0.4880 - val_accuracy: 0.8000\n",
      "Epoch 129/1000\n",
      "801/801 [==============================] - 0s 196us/sample - loss: 0.5805 - accuracy: 0.7179 - val_loss: 0.4867 - val_accuracy: 0.8000\n",
      "Epoch 130/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5488 - accuracy: 0.7291 - val_loss: 0.4790 - val_accuracy: 0.8111\n",
      "Epoch 131/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5479 - accuracy: 0.7353 - val_loss: 0.4793 - val_accuracy: 0.8111\n",
      "Epoch 132/1000\n",
      "801/801 [==============================] - 0s 184us/sample - loss: 0.5782 - accuracy: 0.7129 - val_loss: 0.4822 - val_accuracy: 0.8000\n",
      "Epoch 133/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5757 - accuracy: 0.7191 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 134/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5612 - accuracy: 0.7191 - val_loss: 0.4972 - val_accuracy: 0.8000\n",
      "Epoch 135/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5600 - accuracy: 0.7104 - val_loss: 0.4926 - val_accuracy: 0.8000\n",
      "Epoch 136/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5632 - accuracy: 0.7303 - val_loss: 0.4884 - val_accuracy: 0.8111\n",
      "Epoch 137/1000\n",
      "801/801 [==============================] - 0s 182us/sample - loss: 0.5633 - accuracy: 0.7328 - val_loss: 0.4865 - val_accuracy: 0.8111\n",
      "Epoch 138/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5876 - accuracy: 0.7016 - val_loss: 0.4870 - val_accuracy: 0.8111\n",
      "Epoch 139/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5695 - accuracy: 0.7166 - val_loss: 0.4857 - val_accuracy: 0.8111\n",
      "Epoch 140/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5772 - accuracy: 0.7353 - val_loss: 0.4842 - val_accuracy: 0.8111\n",
      "Epoch 141/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5523 - accuracy: 0.7228 - val_loss: 0.4821 - val_accuracy: 0.8111\n",
      "Epoch 142/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5681 - accuracy: 0.7203 - val_loss: 0.4758 - val_accuracy: 0.8111\n",
      "Epoch 143/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5672 - accuracy: 0.7278 - val_loss: 0.4722 - val_accuracy: 0.8111\n",
      "Epoch 144/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5877 - accuracy: 0.7203 - val_loss: 0.4723 - val_accuracy: 0.8000\n",
      "Epoch 145/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5793 - accuracy: 0.7079 - val_loss: 0.4754 - val_accuracy: 0.8111\n",
      "Epoch 146/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5614 - accuracy: 0.7203 - val_loss: 0.4747 - val_accuracy: 0.8111\n",
      "Epoch 147/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5704 - accuracy: 0.7166 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 148/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5724 - accuracy: 0.7241 - val_loss: 0.4743 - val_accuracy: 0.8000\n",
      "Epoch 149/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5578 - accuracy: 0.7403 - val_loss: 0.4731 - val_accuracy: 0.8111\n",
      "Epoch 150/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5639 - accuracy: 0.7416 - val_loss: 0.4734 - val_accuracy: 0.8000\n",
      "Epoch 151/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5730 - accuracy: 0.7253 - val_loss: 0.4758 - val_accuracy: 0.8111\n",
      "Epoch 152/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5724 - accuracy: 0.7253 - val_loss: 0.4779 - val_accuracy: 0.8111\n",
      "Epoch 153/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5765 - accuracy: 0.7328 - val_loss: 0.4783 - val_accuracy: 0.8111\n",
      "Epoch 154/1000\n",
      "801/801 [==============================] - 0s 186us/sample - loss: 0.5798 - accuracy: 0.7129 - val_loss: 0.4806 - val_accuracy: 0.8111\n",
      "Epoch 155/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5757 - accuracy: 0.7241 - val_loss: 0.4805 - val_accuracy: 0.8111\n",
      "Epoch 156/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5728 - accuracy: 0.7278 - val_loss: 0.4800 - val_accuracy: 0.8000\n",
      "Epoch 157/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5549 - accuracy: 0.7403 - val_loss: 0.4805 - val_accuracy: 0.8111\n",
      "Epoch 158/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5912 - accuracy: 0.7216 - val_loss: 0.4845 - val_accuracy: 0.8111\n",
      "Epoch 159/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5580 - accuracy: 0.7366 - val_loss: 0.4815 - val_accuracy: 0.8111\n",
      "Epoch 160/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5744 - accuracy: 0.7129 - val_loss: 0.4811 - val_accuracy: 0.8111\n",
      "Epoch 161/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5762 - accuracy: 0.7253 - val_loss: 0.4801 - val_accuracy: 0.8111\n",
      "Epoch 162/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5723 - accuracy: 0.7216 - val_loss: 0.4788 - val_accuracy: 0.8000\n",
      "Epoch 163/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5743 - accuracy: 0.7216 - val_loss: 0.4768 - val_accuracy: 0.8000\n",
      "Epoch 164/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5590 - accuracy: 0.7303 - val_loss: 0.4780 - val_accuracy: 0.7889\n",
      "Epoch 165/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5636 - accuracy: 0.7191 - val_loss: 0.4770 - val_accuracy: 0.8111\n",
      "Epoch 166/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5578 - accuracy: 0.7316 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
      "Epoch 167/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5608 - accuracy: 0.7278 - val_loss: 0.4762 - val_accuracy: 0.8111\n",
      "Epoch 168/1000\n",
      "801/801 [==============================] - 0s 183us/sample - loss: 0.5604 - accuracy: 0.7428 - val_loss: 0.4749 - val_accuracy: 0.8111\n",
      "Epoch 169/1000\n",
      "801/801 [==============================] - 0s 185us/sample - loss: 0.5453 - accuracy: 0.7403 - val_loss: 0.4712 - val_accuracy: 0.8111\n",
      "Epoch 170/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5675 - accuracy: 0.7353 - val_loss: 0.4756 - val_accuracy: 0.8111\n",
      "Epoch 171/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5539 - accuracy: 0.7428 - val_loss: 0.4762 - val_accuracy: 0.7889\n",
      "Epoch 172/1000\n",
      "801/801 [==============================] - 0s 178us/sample - loss: 0.5728 - accuracy: 0.7253 - val_loss: 0.4769 - val_accuracy: 0.7889\n",
      "Epoch 173/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5706 - accuracy: 0.7253 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
      "Epoch 174/1000\n",
      "801/801 [==============================] - 0s 183us/sample - loss: 0.5562 - accuracy: 0.7328 - val_loss: 0.4758 - val_accuracy: 0.7889\n",
      "Epoch 175/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5749 - accuracy: 0.7141 - val_loss: 0.4830 - val_accuracy: 0.8000\n",
      "Epoch 176/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5589 - accuracy: 0.7203 - val_loss: 0.4815 - val_accuracy: 0.8000\n",
      "Epoch 177/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5438 - accuracy: 0.7403 - val_loss: 0.4760 - val_accuracy: 0.8000\n",
      "Epoch 178/1000\n",
      "801/801 [==============================] - 0s 175us/sample - loss: 0.5534 - accuracy: 0.7316 - val_loss: 0.4735 - val_accuracy: 0.7889\n",
      "Epoch 179/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5627 - accuracy: 0.7303 - val_loss: 0.4736 - val_accuracy: 0.7889\n",
      "Epoch 180/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5494 - accuracy: 0.7341 - val_loss: 0.4741 - val_accuracy: 0.8000\n",
      "Epoch 181/1000\n",
      "801/801 [==============================] - 0s 184us/sample - loss: 0.5707 - accuracy: 0.7278 - val_loss: 0.4777 - val_accuracy: 0.8000\n",
      "Epoch 182/1000\n",
      "801/801 [==============================] - 0s 181us/sample - loss: 0.5767 - accuracy: 0.7191 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 183/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5557 - accuracy: 0.7403 - val_loss: 0.4751 - val_accuracy: 0.8000\n",
      "Epoch 184/1000\n",
      "801/801 [==============================] - 0s 179us/sample - loss: 0.5647 - accuracy: 0.7253 - val_loss: 0.4710 - val_accuracy: 0.8000\n",
      "Epoch 185/1000\n",
      "801/801 [==============================] - 0s 174us/sample - loss: 0.5653 - accuracy: 0.7303 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 186/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5659 - accuracy: 0.7391 - val_loss: 0.4749 - val_accuracy: 0.8000\n",
      "Epoch 187/1000\n",
      "801/801 [==============================] - 0s 180us/sample - loss: 0.5712 - accuracy: 0.7316 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
      "Epoch 188/1000\n",
      "801/801 [==============================] - 0s 182us/sample - loss: 0.5328 - accuracy: 0.7591 - val_loss: 0.4704 - val_accuracy: 0.8000\n",
      "Epoch 189/1000\n",
      "801/801 [==============================] - 0s 177us/sample - loss: 0.5691 - accuracy: 0.7303 - val_loss: 0.4696 - val_accuracy: 0.7889\n",
      "Epoch 190/1000\n",
      "801/801 [==============================] - 0s 176us/sample - loss: 0.5548 - accuracy: 0.7428 - val_loss: 0.4705 - val_accuracy: 0.7889\n",
      "Epoch 191/1000\n",
      "801/801 [==============================] - 0s 185us/sample - loss: 0.5567 - accuracy: 0.7303 - val_loss: 0.4703 - val_accuracy: 0.7889\n",
      "Epoch 192/1000\n",
      "801/801 [==============================] - 0s 394us/sample - loss: 0.5496 - accuracy: 0.7366 - val_loss: 0.4684 - val_accuracy: 0.7889\n",
      "Epoch 193/1000\n",
      "801/801 [==============================] - 0s 309us/sample - loss: 0.5831 - accuracy: 0.7241 - val_loss: 0.4682 - val_accuracy: 0.7889\n",
      "Epoch 194/1000\n",
      "801/801 [==============================] - 0s 243us/sample - loss: 0.5547 - accuracy: 0.7266 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 195/1000\n",
      "801/801 [==============================] - 0s 305us/sample - loss: 0.5451 - accuracy: 0.7503 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
      "Epoch 196/1000\n",
      "801/801 [==============================] - 0s 279us/sample - loss: 0.5533 - accuracy: 0.7278 - val_loss: 0.4655 - val_accuracy: 0.8000\n",
      "Epoch 197/1000\n",
      "801/801 [==============================] - 0s 192us/sample - loss: 0.5584 - accuracy: 0.7328 - val_loss: 0.4664 - val_accuracy: 0.8000\n",
      "Epoch 198/1000\n",
      "801/801 [==============================] - 0s 389us/sample - loss: 0.5513 - accuracy: 0.7403 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
      "Epoch 199/1000\n",
      "801/801 [==============================] - 0s 612us/sample - loss: 0.5560 - accuracy: 0.7453 - val_loss: 0.4656 - val_accuracy: 0.7889\n",
      "Epoch 200/1000\n",
      "801/801 [==============================] - 0s 554us/sample - loss: 0.5590 - accuracy: 0.7428 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 201/1000\n",
      "801/801 [==============================] - 0s 582us/sample - loss: 0.5479 - accuracy: 0.7378 - val_loss: 0.4713 - val_accuracy: 0.7889\n",
      "Epoch 202/1000\n",
      "801/801 [==============================] - 0s 361us/sample - loss: 0.5399 - accuracy: 0.7403 - val_loss: 0.4689 - val_accuracy: 0.8111\n",
      "Epoch 203/1000\n",
      "801/801 [==============================] - 0s 233us/sample - loss: 0.5480 - accuracy: 0.7416 - val_loss: 0.4648 - val_accuracy: 0.8222\n",
      "Epoch 204/1000\n",
      "801/801 [==============================] - 0s 193us/sample - loss: 0.5553 - accuracy: 0.7416 - val_loss: 0.4642 - val_accuracy: 0.8222\n",
      "Epoch 205/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5553 - accuracy: 0.7391 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 206/1000\n",
      "801/801 [==============================] - 0s 184us/sample - loss: 0.5726 - accuracy: 0.7253 - val_loss: 0.4721 - val_accuracy: 0.8000\n",
      "Epoch 207/1000\n",
      "801/801 [==============================] - 0s 183us/sample - loss: 0.5861 - accuracy: 0.7241 - val_loss: 0.4776 - val_accuracy: 0.8000\n",
      "Epoch 208/1000\n",
      "801/801 [==============================] - 0s 303us/sample - loss: 0.5727 - accuracy: 0.7266 - val_loss: 0.4766 - val_accuracy: 0.8000\n",
      "Epoch 209/1000\n",
      "801/801 [==============================] - 0s 219us/sample - loss: 0.5510 - accuracy: 0.7478 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 210/1000\n",
      "801/801 [==============================] - 0s 230us/sample - loss: 0.5694 - accuracy: 0.7228 - val_loss: 0.4755 - val_accuracy: 0.8000\n",
      "Epoch 211/1000\n",
      "801/801 [==============================] - 0s 219us/sample - loss: 0.5468 - accuracy: 0.7403 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 212/1000\n",
      "801/801 [==============================] - 0s 199us/sample - loss: 0.5445 - accuracy: 0.7516 - val_loss: 0.4711 - val_accuracy: 0.8000\n",
      "Epoch 213/1000\n",
      "801/801 [==============================] - 0s 267us/sample - loss: 0.5737 - accuracy: 0.7216 - val_loss: 0.4687 - val_accuracy: 0.7889\n",
      "Epoch 214/1000\n",
      "801/801 [==============================] - 0s 266us/sample - loss: 0.5641 - accuracy: 0.7278 - val_loss: 0.4675 - val_accuracy: 0.8111\n",
      "Epoch 215/1000\n",
      "801/801 [==============================] - 0s 241us/sample - loss: 0.5486 - accuracy: 0.7503 - val_loss: 0.4617 - val_accuracy: 0.8111\n",
      "Epoch 216/1000\n",
      "801/801 [==============================] - 0s 237us/sample - loss: 0.5593 - accuracy: 0.7353 - val_loss: 0.4601 - val_accuracy: 0.8111\n",
      "Epoch 217/1000\n",
      "801/801 [==============================] - 0s 248us/sample - loss: 0.5470 - accuracy: 0.7378 - val_loss: 0.4603 - val_accuracy: 0.8222\n",
      "Epoch 218/1000\n",
      "801/801 [==============================] - 0s 235us/sample - loss: 0.5769 - accuracy: 0.7303 - val_loss: 0.4608 - val_accuracy: 0.8111\n",
      "Epoch 219/1000\n",
      "801/801 [==============================] - 0s 288us/sample - loss: 0.5353 - accuracy: 0.7391 - val_loss: 0.4628 - val_accuracy: 0.8111\n",
      "Epoch 220/1000\n",
      "801/801 [==============================] - 0s 222us/sample - loss: 0.5607 - accuracy: 0.7253 - val_loss: 0.4623 - val_accuracy: 0.8111\n",
      "Epoch 221/1000\n",
      "801/801 [==============================] - 0s 205us/sample - loss: 0.5558 - accuracy: 0.7378 - val_loss: 0.4679 - val_accuracy: 0.8111\n",
      "Epoch 222/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5918 - accuracy: 0.7241 - val_loss: 0.4703 - val_accuracy: 0.8222\n",
      "Epoch 223/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5383 - accuracy: 0.7428 - val_loss: 0.4698 - val_accuracy: 0.8222\n",
      "Epoch 224/1000\n",
      "801/801 [==============================] - 0s 184us/sample - loss: 0.5650 - accuracy: 0.7378 - val_loss: 0.4700 - val_accuracy: 0.8222\n",
      "Epoch 225/1000\n",
      "801/801 [==============================] - 0s 197us/sample - loss: 0.5446 - accuracy: 0.7478 - val_loss: 0.4716 - val_accuracy: 0.8000\n",
      "Epoch 226/1000\n",
      "801/801 [==============================] - 0s 255us/sample - loss: 0.5598 - accuracy: 0.7353 - val_loss: 0.4664 - val_accuracy: 0.8222\n",
      "Epoch 227/1000\n",
      "801/801 [==============================] - 0s 205us/sample - loss: 0.5572 - accuracy: 0.7416 - val_loss: 0.4667 - val_accuracy: 0.8333\n",
      "Epoch 228/1000\n",
      "801/801 [==============================] - 0s 250us/sample - loss: 0.5442 - accuracy: 0.7428 - val_loss: 0.4662 - val_accuracy: 0.8111\n",
      "Epoch 229/1000\n",
      "801/801 [==============================] - 0s 200us/sample - loss: 0.5564 - accuracy: 0.7441 - val_loss: 0.4695 - val_accuracy: 0.8000\n",
      "Epoch 230/1000\n",
      "801/801 [==============================] - 0s 240us/sample - loss: 0.5562 - accuracy: 0.7478 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 231/1000\n",
      "801/801 [==============================] - 0s 243us/sample - loss: 0.5667 - accuracy: 0.7428 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 232/1000\n",
      "801/801 [==============================] - 0s 216us/sample - loss: 0.5604 - accuracy: 0.7341 - val_loss: 0.4672 - val_accuracy: 0.8000\n",
      "Epoch 233/1000\n",
      "801/801 [==============================] - 0s 188us/sample - loss: 0.5423 - accuracy: 0.7553 - val_loss: 0.4632 - val_accuracy: 0.8111\n",
      "Epoch 234/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5621 - accuracy: 0.7328 - val_loss: 0.4595 - val_accuracy: 0.8111\n",
      "Epoch 235/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5428 - accuracy: 0.7403 - val_loss: 0.4515 - val_accuracy: 0.8222\n",
      "Epoch 236/1000\n",
      "801/801 [==============================] - 0s 197us/sample - loss: 0.5341 - accuracy: 0.7478 - val_loss: 0.4506 - val_accuracy: 0.8222\n",
      "Epoch 237/1000\n",
      "801/801 [==============================] - 0s 203us/sample - loss: 0.5470 - accuracy: 0.7541 - val_loss: 0.4536 - val_accuracy: 0.8222\n",
      "Epoch 238/1000\n",
      "801/801 [==============================] - 0s 183us/sample - loss: 0.5460 - accuracy: 0.7341 - val_loss: 0.4534 - val_accuracy: 0.8333\n",
      "Epoch 239/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5584 - accuracy: 0.7328 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
      "Epoch 240/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5683 - accuracy: 0.7353 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 241/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5620 - accuracy: 0.7291 - val_loss: 0.4589 - val_accuracy: 0.8111\n",
      "Epoch 242/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5619 - accuracy: 0.7428 - val_loss: 0.4596 - val_accuracy: 0.8111\n",
      "Epoch 243/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5531 - accuracy: 0.7428 - val_loss: 0.4615 - val_accuracy: 0.8111\n",
      "Epoch 244/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5525 - accuracy: 0.7291 - val_loss: 0.4632 - val_accuracy: 0.8111\n",
      "Epoch 245/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5414 - accuracy: 0.7478 - val_loss: 0.4604 - val_accuracy: 0.8000\n",
      "Epoch 246/1000\n",
      "801/801 [==============================] - 0s 188us/sample - loss: 0.5696 - accuracy: 0.7403 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 247/1000\n",
      "801/801 [==============================] - 0s 208us/sample - loss: 0.5668 - accuracy: 0.7403 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 248/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5604 - accuracy: 0.7391 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
      "Epoch 249/1000\n",
      "801/801 [==============================] - 0s 190us/sample - loss: 0.5453 - accuracy: 0.7428 - val_loss: 0.4654 - val_accuracy: 0.8000\n",
      "Epoch 250/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5579 - accuracy: 0.7341 - val_loss: 0.4667 - val_accuracy: 0.8000\n",
      "Epoch 251/1000\n",
      "801/801 [==============================] - 0s 188us/sample - loss: 0.5614 - accuracy: 0.7353 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
      "Epoch 252/1000\n",
      "801/801 [==============================] - 0s 193us/sample - loss: 0.5665 - accuracy: 0.7228 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 253/1000\n",
      "801/801 [==============================] - 0s 186us/sample - loss: 0.5358 - accuracy: 0.7553 - val_loss: 0.4659 - val_accuracy: 0.8000\n",
      "Epoch 254/1000\n",
      "801/801 [==============================] - 0s 186us/sample - loss: 0.5436 - accuracy: 0.7503 - val_loss: 0.4579 - val_accuracy: 0.8111\n",
      "Epoch 255/1000\n",
      "801/801 [==============================] - 0s 182us/sample - loss: 0.5477 - accuracy: 0.7441 - val_loss: 0.4596 - val_accuracy: 0.8111\n",
      "Epoch 256/1000\n",
      "801/801 [==============================] - 0s 185us/sample - loss: 0.5602 - accuracy: 0.7341 - val_loss: 0.4609 - val_accuracy: 0.8111\n",
      "Epoch 257/1000\n",
      "801/801 [==============================] - 0s 188us/sample - loss: 0.5677 - accuracy: 0.7179 - val_loss: 0.4662 - val_accuracy: 0.8222\n",
      "Epoch 258/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5572 - accuracy: 0.7453 - val_loss: 0.4673 - val_accuracy: 0.8222\n",
      "Epoch 259/1000\n",
      "801/801 [==============================] - 0s 188us/sample - loss: 0.5577 - accuracy: 0.7428 - val_loss: 0.4666 - val_accuracy: 0.8222\n",
      "Epoch 260/1000\n",
      "801/801 [==============================] - 0s 202us/sample - loss: 0.5419 - accuracy: 0.7391 - val_loss: 0.4608 - val_accuracy: 0.8222\n",
      "Epoch 261/1000\n",
      "801/801 [==============================] - 0s 186us/sample - loss: 0.5611 - accuracy: 0.7366 - val_loss: 0.4607 - val_accuracy: 0.8222\n",
      "Epoch 262/1000\n",
      "801/801 [==============================] - 0s 191us/sample - loss: 0.5500 - accuracy: 0.7366 - val_loss: 0.4555 - val_accuracy: 0.8222\n",
      "Epoch 263/1000\n",
      "801/801 [==============================] - 0s 193us/sample - loss: 0.5798 - accuracy: 0.7316 - val_loss: 0.4600 - val_accuracy: 0.8111\n",
      "Epoch 264/1000\n",
      "801/801 [==============================] - 0s 189us/sample - loss: 0.5394 - accuracy: 0.7491 - val_loss: 0.4595 - val_accuracy: 0.8222\n",
      "Epoch 265/1000\n",
      "801/801 [==============================] - 0s 184us/sample - loss: 0.5503 - accuracy: 0.7328 - val_loss: 0.4578 - val_accuracy: 0.8222\n",
      "Epoch 266/1000\n",
      "801/801 [==============================] - 0s 192us/sample - loss: 0.5475 - accuracy: 0.7428 - val_loss: 0.4560 - val_accuracy: 0.8333\n",
      "Epoch 267/1000\n",
      "801/801 [==============================] - 0s 194us/sample - loss: 0.5510 - accuracy: 0.7391 - val_loss: 0.4563 - val_accuracy: 0.8222\n",
      "Epoch 268/1000\n",
      "801/801 [==============================] - 0s 187us/sample - loss: 0.5390 - accuracy: 0.7603 - val_loss: 0.4590 - val_accuracy: 0.8222\n",
      "Epoch 00268: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x115f4bfd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnClf.fit(x=X1_train_s, y=y1_train,epochs=1000, validation_data=(X1_test_s,y1_test),\n",
    "                   callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. val_accuracy:  0.8333333134651184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a420133d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss_df = pd.DataFrame(dnnClf.history.history)\n",
    "print(\"Max. val_accuracy: \", model_loss_df[\"val_accuracy\"].max())\n",
    "model_loss_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "svmClf = SVC(kernel=\"linear\")\n",
    "svmClf.fit(X1_train,y1_train)\n",
    "svmPreds = svmClf.predict(X1_test)\n",
    "svmAcc = metrics.accuracy_score(svmPreds, y1_test)\n",
    "print(\"SVM Accuracy:\",round(svmAcc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.833\n"
     ]
    }
   ],
   "source": [
    "rfClf = RandomForestRegressor(n_estimators = 200)\n",
    "rfClf.fit(X1_train, y1_train)\n",
    "rfPreds = rfClf.predict(X1_test)\n",
    "rfPreds = [round(i) for i in rfPreds]\n",
    "rfAcc = metrics.accuracy_score(rfPreds,y1_test)\n",
    "print(\"RF Accuracy:\",round(rfAcc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "xgbClf = XGBClassifier(n_estimators=400)\n",
    "xgbClf.fit(X1_train, y1_train)\n",
    "xgbPreds = xgbClf.predict(X1_test)\n",
    "xgbAcc = metrics.accuracy_score(xgbPreds,y1_test)\n",
    "print(\"XGB Accuracy:\",round(xgbAcc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticsRegression Accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "lrClf = LogisticRegression(solver=\"newton-cg\")\n",
    "lrClf.fit(X1_train, y1_train)\n",
    "lrPreds = lrClf.predict(X1_test)\n",
    "lrAcc = metrics.accuracy_score(lrPreds,y1_test)\n",
    "print(\"LogisticsRegression Accuracy:\",round(lrAcc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Submission File :\n",
    "#### Ensemble Method: Combining all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEnsemble(sample):\n",
    "    print(\"=\",end=\"\")\n",
    "    dnnPred = dnnClf.predict(scaler.transform(sample.reshape(1,-1))).tolist()[0][0]\n",
    "    svmPred = svmClf.predict(sample.reshape(1,-1)).tolist()[0]\n",
    "    rfPred = rfClf.predict(sample.reshape(1,-1)).tolist()[0]\n",
    "    xgbPred = xgbClf.predict(sample.reshape(1,-1)).tolist()[0]\n",
    "    lrPred = lrClf.predict(sample.reshape(1,-1)).tolist()[0]\n",
    "\n",
    "    ensPred = []\n",
    "    ensPred.append([dnnPred, svmPred, rfPred, xgbPred, lrPred])\n",
    "\n",
    "\n",
    "    print(ensPred)\n",
    "    ensPred = [round(i) for i in ensPred[0]]\n",
    "    print(ensPred)\n",
    "    \n",
    "    print(max(set(ensPred), key=ensPred.count))\n",
    "    return(max(set(ensPred), key=ensPred.count)) # return mode, i.e: most frequent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df Shape: (418, 10) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  C  Q  S\n",
       "0          892       3    1  34.5      0      0   7.8292  0  1  0\n",
       "1          893       3    0  47.0      1      0   7.0000  0  0  1\n",
       "2          894       2    1  62.0      0      0   9.6875  0  1  0\n",
       "3          895       3    1  27.0      0      0   8.6625  0  0  1\n",
       "4          896       3    0  22.0      1      1  12.2875  0  0  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test_df.drop(\"Ticket\", 1, inplace=True)\n",
    "test_df.drop(\"Name\", 1, inplace=True)\n",
    "test_df.drop(\"Cabin\", 1, inplace=True)\n",
    "\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(value=test_df[\"Embarked\"].mode()[0])\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(value=test_df[\"Age\"].median())\n",
    "test_df[\"Fare\"] = test_df[\"Fare\"].fillna(value=test_df[\"Fare\"].median())\n",
    "\n",
    "\n",
    "test_df[\"Sex\"] = test_df[\"Sex\"].map({\"male\":1, \"female\":0})\n",
    "test_embarked_encoded = pd.get_dummies(test_df[\"Embarked\"])\n",
    "#test_pclass_encoded = pd.get_dummies(test_df[\"Pclass\"], prefix=\"class_\")\n",
    "test_pclass_encoded = pd.get_dummies(test_df[\"Pclass\"], prefix=\"class_\")\n",
    "#test_df.drop([\"Embarked\",\"Pclass\"],axis=1,inplace=True)\n",
    "test_df.drop([\"Embarked\"],axis=1,inplace=True)\n",
    "#test_df = pd.concat([test_df,test_embarked_encoded,test_pclass_encoded],axis=1)\n",
    "test_df = pd.concat([test_df,test_embarked_encoded],axis=1)\n",
    "\n",
    "print(f\"test_df Shape: {test_df.shape} \\n\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=[[0.25201478600502014, 0, 0.03177777777777777, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3832395076751709, 1, 0.19, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.2638761103153229, 0, 0.59, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2552781403064728, 0, 0.66, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.35398104786872864, 1, 0.385, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.2566032111644745, 0, 0.08333333333333331, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5274186730384827, 1, 0.135, 0, 1]]\n",
      "[1, 1, 0, 0, 1]\n",
      "1\n",
      "=[[0.279599130153656, 0, 0.18333333333333335, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.45797213912010193, 1, 0.885, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25413021445274353, 0, 0.045, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25518059730529785, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2850878834724426, 0, 0.18, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8753798007965088, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.26652032136917114, 0, 0.365, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8879660367965698, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8802921175956726, 1, 0.8129166666666667, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.26688840985298157, 0, 0.09796428571428571, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2782690227031708, 0, 0.32, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.37357065081596375, 1, 0.67, 1, 0]]\n",
      "[0, 1, 1, 1, 0]\n",
      "1\n",
      "=[[0.4780523180961609, 1, 0.23, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.34310829639434814, 0, 0.45, 1, 0]]\n",
      "[0, 0, 0, 1, 0]\n",
      "0\n",
      "=[[0.26501554250717163, 0, 0.68, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.8946552872657776, 1, 0.97, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.33711230754852295, 0, 0.59, 1, 1]]\n",
      "[0, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.986761212348938, 1, 0.945, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2519725263118744, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9822271466255188, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27811652421951294, 0, 0.035, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28621894121170044, 0, 0.68, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.2757028341293335, 0, 0.28, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2678089141845703, 0, 0.04, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.269207239151001, 0, 0.095, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.34365114569664, 1, 0.805, 0, 0]]\n",
      "[0, 1, 1, 0, 0]\n",
      "0\n",
      "=[[0.34255245327949524, 1, 0.15, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.3479748070240021, 0, 0.5408333333333333, 1, 1]]\n",
      "[0, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.27852386236190796, 0, 0.52, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.40730318427085876, 1, 0.56, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.40488216280937195, 1, 0.085, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.25557729601860046, 0, 0.005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26141157746315, 0, 0.8150019841269841, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.286411851644516, 0, 0.44375, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.287127822637558, 0, 0.7900654761904761, 1, 1]]\n",
      "[0, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.2538299858570099, 0, 0.11333333333333334, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.7077831029891968, 1, 0.9975, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8876048922538757, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25537681579589844, 0, 0.01, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.34958651661872864, 0, 0.37, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9679518938064575, 1, 0.99, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.37511706352233887, 1, 0.715, 1, 0]]\n",
      "[0, 1, 1, 1, 0]\n",
      "1\n",
      "=[[0.2900390326976776, 0, 0.5416666666666667, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2942003905773163, 0, 0.305, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6117831468582153, 1, 0.72, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8546931147575378, 1, 0.84, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2942604422569275, 0, 0.4, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25826990604400635, 0, 0.04, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2544115483760834, 0, 0.011916666666666666, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2553418278694153, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25437667965888977, 0, 0.075, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9848846197128296, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25614404678344727, 0, 0.11433333333333331, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2698673903942108, 0, 0.3075, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25602903962135315, 0, 0.012484126984126985, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5215655565261841, 1, 0.83, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.6454519629478455, 0, 0.625, 1, 1]]\n",
      "[1, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.7039589285850525, 1, 0.737, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5185718536376953, 1, 0.7, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.28722646832466125, 0, 0.05, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3539416491985321, 0, 0.145, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.8337088227272034, 1, 0.935, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.52299964427948, 1, 0.72, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2557583749294281, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.4081529676914215, 1, 0.28, 1, 1]]\n",
      "[0, 1, 0, 1, 1]\n",
      "1\n",
      "=[[0.35453730821609497, 0, 0.045, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.9834271669387817, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3317851424217224, 0, 0.25, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8794814944267273, 1, 0.63, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27000102400779724, 0, 0.03966666666666666, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.52299964427948, 1, 0.72, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2880920469760895, 0, 0.94, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.309183269739151, 0, 0.205, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2847784161567688, 0, 0.21, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25518059730529785, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26746630668640137, 0, 0.275, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2766803205013275, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.525094211101532, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.4031904935836792, 1, 0.635, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5251728892326355, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2812407314777374, 0, 0.945, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.37440603971481323, 1, 0.115, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.2551652491092682, 0, 0.5015, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.8569942116737366, 1, 0.795, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.35546377301216125, 0, 0.4003333333333333, 1, 1]]\n",
      "[0, 0, 0, 1, 1]\n",
      "0\n",
      "=[[0.2553603947162628, 0, 0.24416666666666667, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8992807865142822, 1, 0.99, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25499194860458374, 0, 0.2836666666666666, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.40400034189224243, 1, 0.585, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25462326407432556, 0, 0.23600000000000002, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9781122803688049, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27009841799736023, 0, 0.065, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25526148080825806, 0, 0.16683333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5219151973724365, 1, 0.66, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25694921612739563, 0, 0.02, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25330430269241333, 0, 0.19203576978576975, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25528451800346375, 0, 0.635, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2711501121520996, 0, 0.0025, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.29224124550819397, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5251550674438477, 1, 0.975, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9754628539085388, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5192976593971252, 1, 0.585, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8851658701896667, 1, 0.975, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27759310603141785, 0, 0.33, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27755364775657654, 0, 0.365, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.34711045026779175, 1, 0.725, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3456469476222992, 0, 0.32, 1, 1]]\n",
      "[0, 0, 0, 1, 1]\n",
      "0\n",
      "=[[0.6751559972763062, 1, 0.965, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.690442681312561, 1, 0.97375, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2508890926837921, 0, 0.3021046176046176, 1, 0]]\n",
      "[0, 0, 0, 1, 0]\n",
      "0\n",
      "=[[0.9806985259056091, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25500229001045227, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3866990804672241, 1, 0.51, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25564929842948914, 0, 0.27, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5038078427314758, 1, 0.89, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.26880523562431335, 0, 0.595, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2554890215396881, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2547193765640259, 0, 0.6280833333333333, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.34676119685173035, 0, 0.265, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.33751508593559265, 1, 0.07, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.2756078839302063, 0, 0.33416666666666667, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25364404916763306, 0, 0.24166666666666667, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.255464106798172, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27771010994911194, 0, 0.19, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27040034532546997, 0, 0.0125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.4054736793041229, 1, 0.11, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.31280121207237244, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.31280121207237244, 1, 0.01, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.8901001214981079, 1, 0.83, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3604349195957184, 0, 0.28, 1, 0]]\n",
      "[0, 0, 0, 1, 0]\n",
      "0\n",
      "=[[0.2719196677207947, 0, 0.06333333333333332, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28557589650154114, 0, 0.905, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.2505638003349304, 0, 0.21, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2906076908111572, 0, 0.525, 0, 1]]\n",
      "[0, 0, 1, 0, 1]\n",
      "0\n",
      "=[[0.2556816637516022, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.287127822637558, 0, 0.7900654761904761, 1, 1]]\n",
      "[0, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.2787875533103943, 0, 0.125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9827422499656677, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2777493894100189, 0, 0.1, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2527986466884613, 0, 0.065, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3732164800167084, 1, 0.57, 0, 0]]\n",
      "[0, 1, 1, 0, 0]\n",
      "0\n",
      "=[[0.2695428431034088, 0, 0.045, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2554253935813904, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8839377164840698, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.4053705930709839, 1, 0.555, 0, 1]]\n",
      "[0, 1, 1, 0, 1]\n",
      "1\n",
      "=[[0.28557589650154114, 0, 0.905, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.36960160732269287, 1, 0.675, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5251830220222473, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.28798821568489075, 0, 0.905, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.7039934992790222, 1, 0.8345, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2550666928291321, 0, 0.705, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.26890474557876587, 0, 0.455, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.36060547828674316, 1, 0.375, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.347319096326828, 0, 0.54, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2732837200164795, 0, 0.08541666666666668, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9783977270126343, 1, 0.8883333333333333, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.4054970443248749, 1, 0.07, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.255136638879776, 0, 0.335, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2776593565940857, 0, 0.26, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2544815242290497, 0, 0.0325, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27765992283821106, 0, 0.255, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.30028030276298523, 0, 0.065, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6469518542289734, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.6953074932098389, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.34328463673591614, 0, 0.655, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.6461347937583923, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9694674611091614, 1, 0.985, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27000102400779724, 0, 0.03966666666666666, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.32935941219329834, 0, 0.39, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8749057650566101, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9890832304954529, 1, 0.935, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2693992853164673, 0, 0.005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6773297190666199, 1, 0.87, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2524753212928772, 0, 0.51275, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.31280121207237244, 1, 0.005, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.26900428533554077, 0, 0.035, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26940032839775085, 0, 0.1075, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2870524525642395, 0, 0.19116666666666668, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.26435214281082153, 0, 0.555, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2643207907676697, 0, 0.37, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2931545078754425, 0, 0.82, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.2545984089374542, 0, 0.015416666666666665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.431500643491745, 0, 0.905, 1, 1]]\n",
      "[0, 0, 1, 1, 1]\n",
      "1\n",
      "=[[0.40304601192474365, 1, 0.78, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27036991715431213, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.40733614563941956, 1, 0.545, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5204516649246216, 1, 0.795, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2762783467769623, 0, 0.985, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.3187391459941864, 0, 0.235, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6317230463027954, 1, 0.76, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2701702117919922, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.35513144731521606, 0, 0.3765, 1, 1]]\n",
      "[0, 0, 0, 1, 1]\n",
      "0\n",
      "=[[0.5309203267097473, 1, 0.265, 0, 1]]\n",
      "[1, 1, 0, 0, 1]\n",
      "1\n",
      "=[[0.27027004957199097, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9763518571853638, 1, 0.965, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2553730905056, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.256562739610672, 0, 0.27375, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25507304072380066, 0, 0.36, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2793785035610199, 0, 0.22699999999999998, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.7048832774162292, 1, 0.475, 1, 0]]\n",
      "[1, 1, 0, 1, 0]\n",
      "1\n",
      "=[[0.31280121207237244, 1, 0.26, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.2877587080001831, 0, 0.16, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.525094211101532, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.31260961294174194, 0, 0.215, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9832823872566223, 1, 0.975, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8667967319488525, 1, 0.975, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.255778044462204, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.7006312012672424, 1, 0.9134166666666667, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25574564933776855, 0, 0.71, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.9680570960044861, 1, 0.82, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.4518526792526245, 1, 0.405, 1, 1]]\n",
      "[0, 1, 0, 1, 1]\n",
      "1\n",
      "=[[0.2555529773235321, 0, 0.105, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5251728892326355, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25479811429977417, 0, 0.01, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26940271258354187, 0, 0.0753452380952381, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2785398066043854, 0, 0.30033333333333334, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8923975825309753, 1, 0.985, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2537342607975006, 0, 0.135, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2527375817298889, 0, 0.0811627539127539, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.344190388917923, 0, 0.475, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2558494806289673, 0, 0.005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.33898910880088806, 0, 0.45, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2783707082271576, 0, 0.565, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.6439473628997803, 1, 0.7475, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9787878394126892, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9671077132225037, 1, 0.765, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.6782686710357666, 1, 0.94, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.32012078166007996, 0, 0.285, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2551795542240143, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27285829186439514, 0, 0.075, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2871538996696472, 0, 0.25, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6992632746696472, 1, 0.8339166666666668, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27844077348709106, 0, 0.05, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6751559972763062, 1, 0.965, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.4705810546875, 1, 0.255, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.6008458733558655, 1, 0.635, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25585851073265076, 0, 0.09333333333333334, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.35169753432273865, 0, 0.415, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.2556513547897339, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25485557317733765, 0, 0.22166666666666665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.255136638879776, 0, 0.335, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2551040053367615, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6974737644195557, 1, 0.9291666666666667, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25574299693107605, 0, 0.19458333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2536301612854004, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2557530999183655, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6633802652359009, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3448832333087921, 1, 0.855, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2934098243713379, 0, 0.3633333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25518059730529785, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2835046648979187, 0, 0.41, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.255136638879776, 0, 0.335, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.40730318427085876, 1, 0.56, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2562418580055237, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3438059091567993, 0, 0.155, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9857439398765564, 1, 0.92, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5147421956062317, 1, 0.88, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2776593565940857, 0, 0.26, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6662395000457764, 1, 0.64, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2698708474636078, 0, 0.05775, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26880282163619995, 0, 0.03, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2691403925418854, 0, 0.015, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2704698145389557, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.4057961702346802, 1, 0.07, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.26531732082366943, 0, 0.995, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.5251728892326355, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5596477389335632, 1, 0.22, 0, 1]]\n",
      "[1, 1, 0, 0, 1]\n",
      "1\n",
      "=[[0.3492816388607025, 1, 0.615, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25423359870910645, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25509849190711975, 0, 0.355, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2931171655654907, 0, 0.2, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27765992283821106, 0, 0.255, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28891876339912415, 0, 0.575, 0, 1]]\n",
      "[0, 0, 1, 0, 1]\n",
      "0\n",
      "=[[0.52783203125, 1, 0.105, 0, 1]]\n",
      "[1, 1, 0, 0, 1]\n",
      "1\n",
      "=[[0.27765992283821106, 0, 0.255, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2994140386581421, 0, 0.15, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25451919436454773, 0, 0.07, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2552768588066101, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.922499418258667, 1, 0.605, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2757028341293335, 0, 0.28, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28941822052001953, 0, 0.005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25498291850090027, 0, 0.08666666666666666, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2546844482421875, 0, 0.08024999999999999, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2942017614841461, 0, 0.305, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27874672412872314, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2555669844150543, 0, 0.06, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5251728892326355, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8879619240760803, 1, 0.815, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.31280121207237244, 0, 0.375, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2666298449039459, 0, 0.97, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.30083784461021423, 0, 0.27, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3847822844982147, 1, 0.075, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.2561453580856323, 0, 0.03, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27816733717918396, 0, 0.035, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2551397979259491, 0, 0.335, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.532233715057373, 1, 0.175, 0, 1]]\n",
      "[1, 1, 0, 0, 1]\n",
      "1\n",
      "=[[0.9737167954444885, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5179356932640076, 1, 0.8, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3292599618434906, 0, 0.37, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2707695960998535, 0, 0.38273015873015864, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25517532229423523, 0, 0.09, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2694064974784851, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25526148080825806, 0, 0.16683333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2778630554676056, 0, 0.04, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27040034532546997, 0, 0.0125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28650644421577454, 0, 0.9733333333333333, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.8891014456748962, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2554580271244049, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6008486747741699, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.34318673610687256, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2698988616466522, 0, 0.1383333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27090004086494446, 0, 0.005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6802884936332703, 1, 0.965, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3516635000705719, 0, 0.445, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2776593565940857, 0, 0.26, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5146604776382446, 1, 0.46, 1, 1]]\n",
      "[1, 1, 0, 1, 1]\n",
      "1\n",
      "=[[0.25518059730529785, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2867417335510254, 0, 0.10658333333333334, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26980146765708923, 0, 0.4995833333333334, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2948678731918335, 0, 0.08875, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27295032143592834, 0, 0.21, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27765992283821106, 0, 0.255, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27086958289146423, 0, 0.16733333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2546595633029938, 0, 0.020583333333333332, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.31280121207237244, 0, 0.27991666666666665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9881227612495422, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.26282888650894165, 0, 0.105, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.4020683765411377, 1, 0.835, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.27040034532546997, 0, 0.0125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.4702226221561432, 1, 0.25, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.2706662118434906, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.7076846361160278, 1, 0.9, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9749182462692261, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2701702117919922, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27927660942077637, 0, 0.057, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.291348397731781, 0, 0.21, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.33035245537757874, 1, 0.69, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2846753001213074, 0, 0.2, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8796883821487427, 1, 0.98, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2551785111427307, 0, 0.085, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.3788129687309265, 1, 0.555, 0, 0]]\n",
      "[0, 1, 1, 0, 0]\n",
      "0\n",
      "=[[0.26677206158638, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8873140215873718, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.7076846361160278, 1, 0.9, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2552781403064728, 0, 0.66, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.9833317995071411, 1, 0.965, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.31280121207237244, 1, 0.35, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.2766808569431305, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.421455055475235, 1, 0.085, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.9747100472450256, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2937122583389282, 0, 0.6170833333333333, 0, 0]]\n",
      "[0, 0, 1, 0, 0]\n",
      "0\n",
      "=[[0.2687861919403076, 0, 0.06833333333333333, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9816586375236511, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.281247615814209, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2686062455177307, 0, 0.485, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8798409104347229, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.9826717376708984, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3395659327507019, 1, 0.11, 0, 0]]\n",
      "[0, 1, 0, 0, 0]\n",
      "0\n",
      "=[[0.2707018256187439, 0, 0.013333333333333332, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.28743860125541687, 0, 0.125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.27034103870391846, 0, 0.175, 1, 0]]\n",
      "[0, 0, 0, 1, 0]\n",
      "0\n",
      "=[[0.25272122025489807, 0, 0.35616315628815665, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25283321738243103, 0, 0.019912753912753912, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.41070792078971863, 1, 0.41, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.37419915199279785, 1, 0.25, 0, 1]]\n",
      "[0, 1, 0, 0, 1]\n",
      "0\n",
      "=[[0.2702839970588684, 0, 0.03516666666666667, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.6199697852134705, 1, 0.985, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25545400381088257, 0, 0.10808333333333332, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26731520891189575, 0, 0.08, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25329533219337463, 0, 0.144363566988567, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26197388768196106, 0, 0.185, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2968081831932068, 0, 0.3, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.8951345086097717, 1, 0.92, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2757788598537445, 0, 0.31, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.26797962188720703, 0, 0.165, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25985100865364075, 0, 0.125, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.874436616897583, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2529449462890625, 0, 0.0005, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.978583574295044, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.25564664602279663, 0, 0.08875, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25233688950538635, 0, 0.05111111111111111, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.8879576921463013, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2683444023132324, 0, 0.0025, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9821305871009827, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2909944951534271, 0, 0.49, 0, 1]]\n",
      "[0, 0, 0, 0, 1]\n",
      "0\n",
      "=[[0.34556663036346436, 0, 0.2, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.29532989859580994, 0, 0.5244444444444444, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n",
      "=[[0.26845577359199524, 0, 0.05625, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.31280121207237244, 0, 0.215, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.5251906514167786, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.3465224504470825, 1, 0.7, 1, 1]]\n",
      "[0, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.5251728892326355, 1, 0.995, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.8925265669822693, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.40761598944664, 1, 0.44, 1, 1]]\n",
      "[0, 1, 0, 1, 1]\n",
      "1\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.9781575798988342, 1, 1.0, 1, 1]]\n",
      "[1, 1, 1, 1, 1]\n",
      "1\n",
      "=[[0.2539937198162079, 0, 0.0, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.25520023703575134, 0, 0.195, 0, 0]]\n",
      "[0, 0, 0, 0, 0]\n",
      "0\n",
      "=[[0.2868892550468445, 0, 0.685, 1, 0]]\n",
      "[0, 0, 1, 1, 0]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TEST = test_df.drop(\"PassengerId\", axis=1).values\n",
    "\n",
    "preds = []\n",
    "for e in X_TEST:\n",
    "    preds.append(predictEnsemble(e))\n",
    "\n",
    "submit = pd.DataFrame(data={\"PassengerId\":test_df[\"PassengerId\"].tolist(), \"Survived\":preds})\n",
    "\n",
    "submit.to_csv('submit.csv',index=False)\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
